# 第5章：数据清洗

数据清洗是数据分析中最重要的步骤之一。在实际工作中，原始数据往往包含错误、重复、缺失值等问题，需要进行清洗和预处理才能用于分析。本章将详细介绍Pandas中的数据清洗技术。

## 5.1 处理缺失值

### 5.1.1 检测缺失值

Pandas使用`NaN`（Not a Number）表示缺失值。

```python
import pandas as pd
import numpy as np

# 创建包含缺失值的数据
data = {
    'A': [1, 2, np.nan, 4, 5],
    'B': [np.nan, 2, 3, 4, 5],
    'C': [1, 2, 3, np.nan, 5],
    'D': [1, 2, 3, 4, 5]
}
df = pd.DataFrame(data)
print("原始数据：")
print(df)

# 检测缺失值
print("\n检测缺失值（返回布尔值）：")
print(df.isnull())

# 检测非缺失值
print("\n检测非缺失值：")
print(df.notnull())

# 统计每列的缺失值数量
print("\n每列的缺失值数量：")
print(df.isnull().sum())

# 统计总的缺失值数量
print("\n总的缺失值数量：", df.isnull().sum().sum())
```

### 5.1.2 删除缺失值

```python
# 删除包含缺失值的行
print("删除包含缺失值的行：")
print(df.dropna())

# 删除包含缺失值的列
print("\n删除包含缺失值的列：")
print(df.dropna(axis=1))

# 删除所有值都是缺失值的行
print("\n删除所有值都是缺失值的行：")
df_with_all_nan = df.copy()
df_with_all_nan.loc[2] = np.nan
print(df_with_all_nan.dropna(how='all'))

# 删除至少有3个非缺失值的行
print("\n保留至少有3个非缺失值的行：")
print(df.dropna(thresh=3))
```

### 5.1.3 填充缺失值

```python
# 用标量值填充
print("用0填充所有缺失值：")
print(df.fillna(0))

# 用不同的值填充不同的列
print("\n用不同的值填充不同的列：")
print(df.fillna({'A': 0, 'B': 1, 'C': 2}))

# 向前填充（用前一个值填充）
print("\n向前填充：")
print(df.fillna(method='ffill'))

# 向后填充（用后一个值填充）
print("\n向后填充：")
print(df.fillna(method='bfill'))

# 用均值填充
print("\n用均值填充：")
print(df.fillna(df.mean()))

# 用中位数填充
print("\n用中位数填充：")
print(df.fillna(df.median()))

# 用众数填充
print("\n用众数填充：")
print(df.fillna(df.mode().iloc[0]))
```

### 5.1.4 插值填充

```python
# 线性插值
print("线性插值：")
print(df.interpolate())

# 多项式插值
print("\n多项式插值：")
print(df.interpolate(method='polynomial', order=2))

# 时间序列插值
dates = pd.date_range('2024-01-01', periods=5)
ts = pd.Series([1, np.nan, np.nan, 4, 5], index=dates)
print("\n时间序列插值：")
print(ts.interpolate(method='time'))
```

## 5.2 处理重复数据

### 5.2.1 检测重复数据

```python
# 创建包含重复数据的DataFrame
data = {
    'A': [1, 2, 2, 3, 3, 3],
    'B': [10, 20, 20, 30, 30, 30],
    'C': [100, 200, 200, 300, 300, 400]
}
df_dup = pd.DataFrame(data)
print("原始数据：")
print(df_dup)

# 检测重复行
print("\n检测重复行：")
print(df_dup.duplicated())

# 检测基于特定列的重复
print("\n基于列A检测重复：")
print(df_dup.duplicated(subset=['A']))

# 保留最后一个重复项
print("\n保留最后一个重复项：")
print(df_dup.duplicated(keep='last'))
```

### 5.2.2 删除重复数据

```python
# 删除重复行
print("删除重复行：")
print(df_dup.drop_duplicates())

# 基于特定列删除重复
print("\n基于列A和B删除重复：")
print(df_dup.drop_duplicates(subset=['A', 'B']))

# 保留最后一个重复项
print("\n保留最后一个重复项：")
print(df_dup.drop_duplicates(keep='last'))

# 保留第一个和最后一个都删除（只删除所有重复项）
print("\n删除所有重复项：")
print(df_dup.drop_duplicates(keep=False))
```

## 5.3 处理异常值

### 5.3.1 使用统计方法检测异常值

```python
# 创建数据
np.random.seed(42)
data = pd.Series(np.random.randn(100) * 10 + 50)
# 添加一些异常值
data.iloc[0] = 150
data.iloc[1] = -50
data.iloc[2] = 200

print("数据统计：")
print(data.describe())

# 使用3倍标准差检测异常值
mean = data.mean()
std = data.std()
outliers = (data < mean - 3*std) | (data > mean + 3*std)
print(f"\n异常值（3倍标准差）：")
print(data[outliers])

# 使用IQR（四分位距）检测异常值
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
outliers_iqr = (data < Q1 - 1.5*IQR) | (data > Q3 + 1.5*IQR)
print(f"\n异常值（IQR方法）：")
print(data[outliers_iqr])
```

### 5.3.2 处理异常值

```python
# 删除异常值
print("删除异常值：")
cleaned_data = data[~outliers_iqr]
print(f"原始数据长度: {len(data)}, 清洗后长度: {len(cleaned_data)}")

# 替换异常值为边界值（Winsorization）
print("\n替换异常值为边界值：")
lower_bound = Q1 - 1.5*IQR
upper_bound = Q3 + 1.5*IQR
data_winsorized = data.clip(lower=lower_bound, upper=upper_bound)
print(data_winsorized[outliers_iqr])

# 替换异常值为中位数
print("\n替换异常值为中位数：")
median = data.median()
data_median = data.copy()
data_median[outliers_iqr] = median
print(data_median.describe())
```

## 5.4 数据类型转换

### 5.4.1 基本类型转换

```python
# 创建混合类型数据
data = {
    'A': ['1', '2', '3', '4', '5'],
    'B': ['1.1', '2.2', '3.3', '4.4', '5.5'],
    'C': ['True', 'False', 'True', 'False', 'True'],
    'D': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05']
}
df_types = pd.DataFrame(data)
print("原始数据类型：")
print(df_types.dtypes)

# 转换为整数
df_types['A'] = df_types['A'].astype(int)
print("\n列A转换为整数：")
print(df_types['A'].dtype)

# 转换为浮点数
df_types['B'] = df_types['B'].astype(float)
print("列B转换为浮点数：")
print(df_types['B'].dtype)

# 转换为布尔值
df_types['C'] = df_types['C'].map({'True': True, 'False': False})
print("列C转换为布尔值：")
print(df_types['C'].dtype)

# 转换为日期时间
df_types['D'] = pd.to_datetime(df_types['D'])
print("列D转换为日期时间：")
print(df_types['D'].dtype)

print("\n转换后的数据类型：")
print(df_types.dtypes)
```

### 5.4.2 处理转换错误

```python
# 创建包含无效值的数据
data_invalid = pd.Series(['1', '2', 'abc', '4', '5'])

# 默认会报错
try:
    result = data_invalid.astype(int)
except ValueError as e:
    print(f"转换错误: {e}")

# 使用errors='coerce'将无效值转换为NaN
result = pd.to_numeric(data_invalid, errors='coerce')
print("\n使用errors='coerce'：")
print(result)

# 使用errors='ignore'忽略错误
result = pd.to_numeric(data_invalid, errors='ignore')
print("\n使用errors='ignore'：")
print(result)
```

## 5.5 字符串清洗

### 5.5.1 去除空白字符

```python
# 创建包含空白字符的数据
data = pd.Series(['  hello  ', 'world  ', '  pandas', '  data  '])
print("原始数据：")
print(data)

# 去除两端空白
print("\n去除两端空白：")
print(data.str.strip())

# 去除左侧空白
print("\n去除左侧空白：")
print(data.str.lstrip())

# 去除右侧空白
print("\n去除右侧空白：")
print(data.str.rstrip())
```

### 5.5.2 大小写转换

```python
data = pd.Series(['Hello', 'WORLD', 'Pandas', 'DATA'])

print("转换为小写：")
print(data.str.lower())

print("\n转换为大写：")
print(data.str.upper())

print("\n首字母大写：")
print(data.str.capitalize())

print("\n标题格式（每个单词首字母大写）：")
print(data.str.title())
```

### 5.5.3 替换字符串

```python
data = pd.Series(['hello world', 'pandas data', 'python programming'])

# 简单替换
print("替换'o'为'0'：")
print(data.str.replace('o', '0'))

# 正则表达式替换
print("\n使用正则表达式替换数字：")
data_with_numbers = pd.Series(['abc123', 'def456', 'ghi789'])
print(data_with_numbers.str.replace(r'\d+', 'XXX', regex=True))
```

## 5.6 数据标准化和归一化

### 5.6.1 标准化（Z-score标准化）

```python
# 创建数据
data = pd.DataFrame({
    'A': [1, 2, 3, 4, 5],
    'B': [10, 20, 30, 40, 50],
    'C': [100, 200, 300, 400, 500]
})
print("原始数据：")
print(data)

# Z-score标准化
standardized = (data - data.mean()) / data.std()
print("\n标准化后的数据：")
print(standardized)

print("\n验证标准化（均值应接近0，标准差应接近1）：")
print(f"均值: \n{standardized.mean()}")
print(f"\n标准差: \n{standardized.std()}")
```

### 5.6.2 归一化（Min-Max归一化）

```python
# Min-Max归一化到[0, 1]
normalized = (data - data.min()) / (data.max() - data.min())
print("归一化到[0, 1]：")
print(normalized)

# 归一化到自定义区间[-1, 1]
min_val = -1
max_val = 1
normalized_custom = (data - data.min()) / (data.max() - data.min()) * (max_val - min_val) + min_val
print("\n归一化到[-1, 1]：")
print(normalized_custom)
```

## 5.7 数据离散化

### 5.7.1 等宽离散化

```python
# 创建连续数据
ages = pd.Series([18, 22, 25, 27, 30, 35, 40, 45, 50, 55, 60, 65])
print("原始年龄数据：")
print(ages)

# 等宽离散化（分成4个区间）
bins = pd.cut(ages, bins=4)
print("\n等宽离散化（4个区间）：")
print(bins)

# 自定义区间
custom_bins = [0, 25, 40, 60, 100]
labels = ['青年', '中年', '壮年', '老年']
age_groups = pd.cut(ages, bins=custom_bins, labels=labels)
print("\n自定义区间离散化：")
print(age_groups)
```

### 5.7.2 等频离散化

```python
# 等频离散化（每个区间包含相同数量的样本）
quantile_bins = pd.qcut(ages, q=4)
print("等频离散化（4个区间）：")
print(quantile_bins)

# 查看每个区间的计数
print("\n每个区间的计数：")
print(quantile_bins.value_counts().sort_index())
```

## 5.8 数据验证

### 5.8.1 数据范围验证

```python
# 创建数据
data = pd.DataFrame({
    'age': [25, 30, -5, 150, 40],
    'score': [85, 92, 78, 105, 88],
    'salary': [5000, 6000, 7000, -1000, 8000]
})
print("原始数据：")
print(data)

# 检查年龄是否在合理范围内
age_valid = (data['age'] >= 0) & (data['age'] <= 120)
print("\n年龄验证：")
print(data[~age_valid])

# 检查分数是否在0-100之间
score_valid = (data['score'] >= 0) & (data['score'] <= 100)
print("\n分数验证：")
print(data[~score_valid])

# 检查工资是否为正数
salary_valid = data['salary'] > 0
print("\n工资验证：")
print(data[~salary_valid])
```

### 5.8.2 数据一致性验证

```python
# 创建数据
data = pd.DataFrame({
    'start_date': pd.to_datetime(['2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01']),
    'end_date': pd.to_datetime(['2024-01-31', '2024-01-15', '2024-03-31', '2024-04-30']),
    'price': [100, 200, 300, 400],
    'quantity': [10, 5, 8, 3],
    'total': [1000, 900, 2400, 1200]
})
print("原始数据：")
print(data)

# 验证结束日期是否晚于开始日期
date_valid = data['end_date'] >= data['start_date']
print("\n日期一致性验证：")
print(data[~date_valid])

# 验证总价是否等于单价*数量
total_valid = data['total'] == data['price'] * data['quantity']
print("\n总价一致性验证：")
print(data[~total_valid])
```

## 5.9 综合案例：清洗真实数据集

```python
# 创建一个模拟的真实数据集
np.random.seed(42)
n = 100

data = pd.DataFrame({
    'id': range(1, n+1),
    'name': ['User' + str(i) for i in range(1, n+1)],
    'age': np.random.randint(18, 80, n),
    'gender': np.random.choice(['M', 'F', 'm', 'f', 'Male', 'Female', np.nan], n),
    'email': ['user' + str(i) + '@email.com' if i % 10 != 0 else np.nan
              for i in range(1, n+1)],
    'salary': np.random.randint(3000, 15000, n),
    'department': np.random.choice(['Sales', 'IT', 'HR', 'sales', 'it', np.nan], n),
    'join_date': pd.date_range('2020-01-01', periods=n, freq='3D')
})

# 添加一些异常值
data.loc[0, 'age'] = -5
data.loc[1, 'age'] = 200
data.loc[2, 'salary'] = -1000
data.loc[5:10, 'name'] = 'User5'  # 添加重复名字

print("原始数据概览：")
print(data.head(10))
print(f"\n数据形状: {data.shape}")
print("\n数据类型：")
print(data.dtypes)
print("\n缺失值统计：")
print(data.isnull().sum())

# 开始清洗

# 1. 处理重复数据
print("\n1. 删除完全重复的行")
data = data.drop_duplicates()
print(f"删除后的数据形状: {data.shape}")

# 2. 处理缺失值
print("\n2. 处理缺失值")
# gender填充为'Unknown'
data['gender'] = data['gender'].fillna('Unknown')
# email填充为默认值
data['email'] = data['email'].fillna('no_email@example.com')
# department填充为众数
data['department'] = data['department'].fillna(data['department'].mode()[0])
print("缺失值处理后：")
print(data.isnull().sum())

# 3. 标准化性别数据
print("\n3. 标准化性别数据")
gender_mapping = {
    'M': 'Male',
    'm': 'Male',
    'Male': 'Male',
    'F': 'Female',
    'f': 'Female',
    'Female': 'Female',
    'Unknown': 'Unknown'
}
data['gender'] = data['gender'].map(gender_mapping)
print("性别分布：")
print(data['gender'].value_counts())

# 4. 标准化部门数据
print("\n4. 标准化部门数据")
data['department'] = data['department'].str.title()
print("部门分布：")
print(data['department'].value_counts())

# 5. 处理年龄异常值
print("\n5. 处理年龄异常值")
age_valid = (data['age'] >= 18) & (data['age'] <= 80)
print(f"异常年龄数据：")
print(data[~age_valid][['id', 'name', 'age']])
# 用中位数替换异常值
median_age = data.loc[age_valid, 'age'].median()
data.loc[~age_valid, 'age'] = median_age

# 6. 处理工资异常值
print("\n6. 处理工资异常值")
salary_valid = data['salary'] > 0
print(f"异常工资数据：")
print(data[~salary_valid][['id', 'name', 'salary']])
# 用部门平均工资替换
data.loc[~salary_valid, 'salary'] = data.groupby('department')['salary'].transform('mean')

# 7. 去除邮箱空格
print("\n7. 清理邮箱格式")
data['email'] = data['email'].str.strip().str.lower()

# 8. 数据验证
print("\n8. 最终数据验证")
print(f"数据形状: {data.shape}")
print(f"缺失值总数: {data.isnull().sum().sum()}")
print(f"重复行数: {data.duplicated().sum()}")
print(f"年龄范围: {data['age'].min()} - {data['age'].max()}")
print(f"工资范围: {data['salary'].min()} - {data['salary'].max()}")

print("\n清洗后的数据样例：")
print(data.head(10))

# 保存清洗后的数据
# data.to_csv('cleaned_data.csv', index=False)
print("\n数据清洗完成！")
```

## 5.10 数据清洗最佳实践

### 5.10.1 数据清洗流程

1. **数据探索**
   - 查看数据的形状、类型
   - 统计缺失值、重复值
   - 查看数据分布

2. **数据清洗**
   - 处理缺失值
   - 删除重复数据
   - 处理异常值
   - 标准化数据格式

3. **数据验证**
   - 验证数据范围
   - 验证数据一致性
   - 验证数据完整性

4. **数据文档**
   - 记录清洗步骤
   - 记录数据变化
   - 保存清洗前后的数据

### 5.10.2 常见陷阱

```python
# 1. 直接修改原始数据
# 错误做法
df_original = pd.DataFrame({'A': [1, 2, 3]})
df = df_original
df['A'] = df['A'] * 2  # 这会修改原始数据

# 正确做法
df = df_original.copy()
df['A'] = df['A'] * 2

# 2. 忘记处理链式赋值警告
df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
# 错误做法（可能产生警告）
# df[df['A'] > 1]['B'] = 0

# 正确做法
df.loc[df['A'] > 1, 'B'] = 0

# 3. 不恰当的缺失值处理
# 删除缺失值前要考虑数据量和缺失比例
print(f"缺失值比例: {df.isnull().sum() / len(df)}")

# 4. 忘记重置索引
df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})
df_filtered = df[df['A'] > 2]
print("过滤后的索引：", df_filtered.index.tolist())
df_filtered = df_filtered.reset_index(drop=True)
print("重置后的索引：", df_filtered.index.tolist())
```

## 5.11 练习题

1. **基础练习**：创建一个包含缺失值和重复值的DataFrame，使用不同方法处理它们。

2. **异常值检测**：使用3倍标准差和IQR两种方法检测异常值，比较结果的差异。

3. **数据标准化**：对一个多列数据集进行标准化和归一化，观察结果的差异。

4. **字符串清洗**：处理包含不规范格式的电话号码、邮箱等数据。

5. **综合案例**：清洗一个包含用户信息的数据集，包括姓名、年龄、邮箱、电话等字段。

## 5.12 小结

本章介绍了Pandas中的数据清洗技术：

- **缺失值处理**：检测、删除、填充和插值
- **重复数据处理**：检测和删除重复行
- **异常值处理**：检测和处理异常值
- **数据类型转换**：转换数据类型和处理转换错误
- **字符串清洗**：去除空白、大小写转换、替换
- **数据标准化**：Z-score标准化和Min-Max归一化
- **数据离散化**：等宽和等频离散化
- **数据验证**：范围验证和一致性验证
- **最佳实践**：数据清洗流程和常见陷阱

数据清洗是数据分析的基础，掌握这些技术对于处理真实数据集非常重要。

## 下一章

在下一章中，我们将学习**数据合并和连接**，包括concat、merge、join等操作。
